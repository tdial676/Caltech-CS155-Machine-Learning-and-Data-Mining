{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuhwnMKgmT3v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST('./data', train=True, download=True,  # Downloads into a directory ../data\n",
        "                               transform=transforms.ToTensor())\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=False,  # No need to download again\n",
        "                              transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "LA4Kp-synIWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-B**"
      ],
      "metadata": {
        "id": "hpPp1KLtmyYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    # In problem 2, we don't use the 2D structure of an image at all. Our network\n",
        "    # takes in a flat vector of the pixel values as input.\n",
        "    nn.Flatten(),  \n",
        "    nn.Linear(784, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(100, 10)\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqrV3mBNnPNU",
        "outputId": "d9c98178-3d58-4dcd-e117-bbec8950a49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WiYy0NjrpMFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) "
      ],
      "metadata": {
        "id": "acqfkwS1pTCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9wt_0YZpU7t",
        "outputId": "06c4696c-c252-4a8d-f1b9-f7f648ea4b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.1254\n",
            "Train Epoch: 2  Loss: 0.2105\n",
            "Train Epoch: 3  Loss: 0.1366\n",
            "Train Epoch: 4  Loss: 0.0387\n",
            "Train Epoch: 5  Loss: 0.1046\n",
            "Train Epoch: 6  Loss: 0.0460\n",
            "Train Epoch: 7  Loss: 0.0662\n",
            "Train Epoch: 8  Loss: 0.0623\n",
            "Train Epoch: 9  Loss: 0.0286\n",
            "Train Epoch: 10  Loss: 0.0502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb1Hkc1JpZFU",
        "outputId": "616012ad-c1b1-455c-d9b9-89058c37b142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0028, Accuracy: 9757/10000 (97.5700)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-C**"
      ],
      "metadata": {
        "id": "COXNWA4orfdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Flatten(),  \n",
        "    nn.Linear(784, 148),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.23),\n",
        "    nn.Linear(148, 52),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.23),\n",
        "    nn.Linear(52, 10)\n",
        ")\n",
        "print(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a576a8fb-f932-4137-b446-4e58a1332eff",
        "id": "C_rwZSJNq-HF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=148, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.23, inplace=False)\n",
            "  (4): Linear(in_features=148, out_features=52, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.23, inplace=False)\n",
            "  (7): Linear(in_features=52, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "X7FhKB9hrrMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) "
      ],
      "metadata": {
        "id": "ZWAjhS8DrrMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model2.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model2(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bf11de-d6c1-4063-a132-d423b6a4814f",
        "id": "zFczPSeOq-HN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.0176\n",
            "Train Epoch: 2  Loss: 0.0041\n",
            "Train Epoch: 3  Loss: 0.0026\n",
            "Train Epoch: 4  Loss: 0.1498\n",
            "Train Epoch: 5  Loss: 0.0247\n",
            "Train Epoch: 6  Loss: 0.0029\n",
            "Train Epoch: 7  Loss: 0.0269\n",
            "Train Epoch: 8  Loss: 0.0231\n",
            "Train Epoch: 9  Loss: 0.0023\n",
            "Train Epoch: 10  Loss: 0.0207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model2(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ae8975-36dc-4191-d66d-2fd79d3541ba",
        "id": "vmT2D8dCq-HO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0026, Accuracy: 9807/10000 (98.0700)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-D**"
      ],
      "metadata": {
        "id": "t2pcMAvVr4uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = nn.Sequential(\n",
        "    # In problem 2, we don't use the 2D structure of an image at all. Our network\n",
        "    # takes in a flat vector of the pixel values as input.\n",
        "    nn.Flatten(),  \n",
        "    nn.Linear(784, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Linear(500, 350),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Linear(350, 150),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.25),\n",
        "    nn.Linear(150, 10)\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa999c9-a394-4228-c4fe-820b50deaf2d",
        "id": "nSFmC8VNsAaM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model3.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "IS0thGkmsAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) "
      ],
      "metadata": {
        "id": "-l2Lo8LgsAaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model3.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model3(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4edb58-e839-4656-9466-5be192987a71",
        "id": "R3zPK6TPsAaQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.0042\n",
            "Train Epoch: 2  Loss: 0.0001\n",
            "Train Epoch: 3  Loss: 0.0046\n",
            "Train Epoch: 4  Loss: 0.0184\n",
            "Train Epoch: 5  Loss: 0.1198\n",
            "Train Epoch: 6  Loss: 0.0114\n",
            "Train Epoch: 7  Loss: 0.0023\n",
            "Train Epoch: 8  Loss: 0.0013\n",
            "Train Epoch: 9  Loss: 0.0001\n",
            "Train Epoch: 10  Loss: 0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model3.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model3(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ef050f-6594-4279-a0a3-ec43ef6a91ff",
        "id": "3BLwhFvcsAaR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0029, Accuracy: 9853/10000 (98.5300)\n"
          ]
        }
      ]
    }
  ]
}